{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import h5py\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D, add\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, ZeroPadding2D\n",
    "from keras import regularizers\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('dataset/hdf5_train_dataset.hdf5', 'r')\n",
    "    train_set_x_orig = np.array(train_dataset['train_set_X'][:])\n",
    "    train_set_y_orig = np.array(train_dataset['train_set_Y'][:])\n",
    "    \n",
    "    test_dataset = h5py.File('dataset/hdf5_test_dataset.hdf5', 'r')\n",
    "    test_set_x_orig = np.array(test_dataset['test_set_X'][:])\n",
    "    test_set_y_orig = np.array(test_dataset['test_set_Y'][:])\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    X -- input data, of shape (input size, number of examples)(m, n_H, n_W, n_C)\n",
    "    Y -- true 'label' vector (containing 0 if cat, 1 if non-cat) of shape (1, number of examples)(m,n_y)\n",
    "    mini_batch_size -- size of minibatches, integer\n",
    "    \"\"\"\n",
    "    m = X.shape()   #number of examples\n",
    "    mini_batches = []\n",
    "    \n",
    "    #Step 1 -- Shuffle X and Y\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "    \n",
    "    #Step 2 -- partition of X and Y minus the end case\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size)\n",
    "    for i in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[i*mini_batch_size: i* mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[i*mini_batch_size: i*mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "        \n",
    "    #handling the end case (last_mini_batch < mini_batch_size)\n",
    "    if m%mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size:m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches*mini_batch_size:m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "        \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y,C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation_for_predict(X, parameters):\n",
    "    \n",
    "    \"\"\"Implement Linear -> Relu -> Linear -> ReLu -> Softmax\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit \n",
    "    \n",
    "    \"\"\"\n",
    "    #Retrieve the parameters from the dictionary 'parameters'\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1,X), b1)\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2)\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    \n",
    "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
    "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
    "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
    "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
    "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
    "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
    " \n",
    "    params = {\"W1\" : W1,\n",
    "             \"b1\" : b1,\n",
    "             \"W2\" : W2,\n",
    "             \"b2\" : b2, \n",
    "             \"W3\" : W3,\n",
    "              \"b3\" : b3\n",
    "             }\n",
    "    x = tf.placeholder(\"float\", [12288,1])\n",
    "    \n",
    "    z3 = forward_propagation_for_predict(x, params)\n",
    "    p = tf.argmax(z3)\n",
    "    sess = tf.Session()\n",
    "    prediction = sess.run(p, feed_dict = {x:X})\n",
    "    \n",
    "    return prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
